\chapter{Computability} \label{sec:background-computability}

\begin{quotation}

\footnotesize\sffamily\itshape

\begin{flushright}

The ``computable'' numbers may be described briefly as the real numbers whose
expressions as a decimal are calculable by finite means.

\smallbreak

\upshape

--- ALAN TURING, {\itshape Proceedings of The London Mathematical Society} (1936-7)

\end{flushright}

\end{quotation}

The theory of computability is concerned with the nature of computation. It
originated in the 1930s with the celebrated works of G\"odel, Kleene, Church,
Post, Turing, et al.  Fundamental to the field is the Church-Turing thesis,
which proposes that the natural phenomena of computation is captured by the
definition of computation with a Turing machine.

We begin with a brief discussion about the intuitive notion of computation,
leading way for a formal\footnote{By ``formal'', in this chapter and the next,
we mean built atop the mathematical foundations as outlined in
\refSection{preface:mathematical-foundations}. It is an interesting thesis in
its own right to consider an exposition of computability and complexity theory
as based solely on the Church-Turing thesis as an axiom. Some work in this
direction appears in \cite{markov-1954}.} definition of computation with a
Turing machine, culminating in an exposition of the Church-Turing thesis.

\section{Notion of computation}

\begin{notion} A problem is ``computable'' if it can be solved by transforming
a mathematical object, without ingenuity. \end{notion}

That is, ``computation'' is the transformation of a mathematical object,
without ingenuity.  Any attempt at a more definite notion of computation seems
to arrive at a philosophical impasse, where the notions of ``mathematical
object'', ``transformation'', and ``ingenuity'' form a philosophical conundrum.

The indefinite notion however, provides for some leeway to state a couple
hyptheses about the nature of computation:

\begin{hypothesis} \label{ths:do-nothing} Doing nothing is computable.
\end{hypothesis}

\begin{hypothesis} \label{ths:problem-composition} If a problem $P$ can be
solved by solving a computable problem $Q$, immediately followed by solving a
computable problem $R$, then $P$ itself is computable. \end{hypothesis}

The second hypothesis clearly holds as nothing is done other than solve the two
computable problems.  So any problem which can be solved by solving a finite
sequence of computable problems, is itself computable. We now arrive at an
intuitive notion of an algorithm:

\begin{notion} \label{ntn:problem-algorithm} An ``algorithm'' is a
specification of how a problem can be solved by solving a finite sequence of
computable problems, called ``steps''.\end{notion}

Such indefinite notions are useful for little else. We are left to fall prey to
some choice of formalism.

\section{Turing machines}

To this end, the notion of computation by means of Turing machine, due to Alan
Turing\cite{turing-1936-7}, forms perhaps the most classical conceptualization
of computation. The conceptualization below is heavily inspired by the those
that appear in \cite{tourlakis-1984}, \cite{jones-1997},
\cite{homer-selman-2011}, and \cite{sipser-2013}, but slightly differs from all
of them.

A \textbf{Turing machine} is a symbol-manipulating machine, working with a
1-dimensional, unbounded tape divided into discrete, equally sized squares.
Each square is occupied by a symbol drawn from the \textbf{tape alphabet} of
the machine.  The tape alphabet consists of the \textbf{input/output alphabet},
usually denoted $\Sigma$, and a special \textbf{blank symbol}, written \blank,
which is not in $\Sigma$. The tape has a left edge, but extends into infinity
to the right, filled with blank symbols.

% Inspired by
% http://tex.stackexchange.com/questions/203257/tikz-chains-with-one-side-of-the-leftmost-node-thickbold

\begin{figure}[h!]
\centering
\begin{tikzpicture}
  \tikzset{tape/.style={minimum size=.7cm, draw}}
  \begin{scope}[start chain=0 going right, node distance=0mm]
   \foreach \x [count=\i] in {\symb{1}, \symb{0}, \symb{1}, \symb{0}, \symb{1}, \symb{0}, \blank, \blank, \blank} {
    \ifnum\i=9 % if last node reset outer sep to 0pt
      \node [on chain=0, tape, outer sep=0pt] (n\i) {\x};
      \draw (n\i.north east) -- ++(.1,0) decorate [decoration={zigzag, segment length=.12cm, amplitude=.02cm}] {-- ($(n\i.south east)+(+.1,0)$)} -- (n\i.south east) -- cycle;
     \else
      \node [on chain=0, tape] (n\i) {\x};
     \fi
   }
   \node [right=.25cm of n9] {$\cdots$};
  \end{scope}
\end{tikzpicture}
\caption[]{Schematic of a Turing tape with $\Sigma=\set{\symb{0},\symb{1}}$.}
\label{fig:turing-tape}
\end{figure}

A Turing machine is always in one of a finite, nonempty set of \textbf{states},
also called the \textbf{state alphabet}, and has a tape head, always
overlooking a particular square on the tape. A Turing machine ``computes'' by
transitioning between states and working with the tape head.

The transition from one state to the next is uniquely determined by the current
state, and the symbol read off the overlooked square. A state transition bears
with it writing a new symbol to the overlooked square, and moving the tape head
one square to the left, or one square to the right.

There are two distinguished states, the \textbf{starting state}, usually
denoted \qstart, and the \textbf{halting state}, usually denoted \qhalt. A
Turing machine \textbf{starts} a computation by entering the state \qstart,
overlooking the square at the left end of the tape. A Turing machine
\textbf{halts}, i.e.  performs no further state transitions, if it ever
transitions to the state \qhalt. A halting computation is a finite sequence of
state transitions.

We now formalise these notions as follows:

\begin{definition} A Turing machine (TM) $M$ is a 5-tuple $\p{Q, \qstart,
\qhalt, \Gamma, \delta}$, where

\begin{enumerate}

\item $Q$ is the state alphabet,

\item $\qstart \in Q$ is the starting state,

\item $\qhalt \in Q$ is the halting state,

\item $\Gamma = \Sigma \cup \set{\blank}$ is the tape alphabet, where $\Sigma$
is the input/output alphabet, and $\Sigma \cap \set{\blank} = \emptyset$

\item $\delta : Q \setminus \set{\qhalt} \times \Gamma \rightarrow Q \times
\Gamma \times \set{\symb{L}, \symb{R}}$ is the (total) transition function.

\end{enumerate}

We will omit stating the components of a TM, when they are clear from context.

\end{definition}

\begin{definition} An $M$-\textbf{configuration} of a TM $M$, is a 3-tuple,
written $uqv$, where $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$. If
$v=\varepsilon$, it can be regarded as if $v=\blank$. \end{definition}

We will omit stating that $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$ when
this is clear from context. The additional permission to regard an empty $v$ as
a $v$ containing a blank symbol facilitates the notion of an infinite tape.
This is illustrated by an example further below.

\begin{definition} An $M$-configuration $C_x$ \textbf{yields} an
$M$-configuration $C_y$, written $C_x\leadsto C_y$, iff either

\begin{enumerate}

\item $\delta\p{q_x,a}=\p{q_y,b,\goright}$, $C_x=uq_xav$, and $C_y=ubq_yv$,

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=ucq_xav$, and $C_y=uq_ycbv$,
or

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=q_xbv$,  and $C_y=q_ybv$;

where $a,b,c\in\Sigma$, and $q_x,q_y\in Q$.

\end{enumerate}

\end{definition}

\begin{definition}

A TM $M$ halts with output $y\in\Sigma^*$ on input $x\in\Sigma^*$, written
$M\p{x}\downarrow y$, iff there exists a finite sequence of $M$-configurations,
$\chev{C_1,C_2,\ldots, C_k}$, of length $k\in\mathbb{N}$, such that

\begin{enumerate}

\item $C_1=\qstart x$,

\item $C_i\leadsto C_{i+1}$ for all $1\leq i < k$,

\item $C_k=u\qhalt yv$.

\end{enumerate}

\end{definition}

Note, in particular that the ``tape'' of a TM in such a formalisation is not
infinite, and rather, finite but extensible. As an example, consider a TM $M$,
where $\Sigma=\set{\symb{\#}}$ and $\delta\p{\qstart, \blank} =
\p{\qhalt,\#,\goleft}$. We have that $\qstart\leadsto\qhalt\#$ and
$M\p{}\downarrow\#$.

\section{Minor variants}

In this section, we give some justification for our definition of Turing
machines by considering how it can simulate various variants often found in the
literature. The ability of our Turing machines to simulate these variants
builds confidence in our definition, and permits us to stand on the shoulders
of giants, and state the Church-Turing thesis based on our notion of Turing
machines.

\subsection{Don't move the tape head}

In our definition of a Turing machine, each transition bore with it the
movement of the tape head either left or right. Some variants will also permit
the tape head to stay where it is. 

Our machines can simulate such machines by having two state transitions, first
moving left, then right whenever we wish to simulate a state transition where
the tape head does not move.

\subsection{A larger tape alphabet}

In our definition of a Turing machine we defined the tape alphabet as $\Gamma =
\Sigma \cup \set{\blank}$, where $\Sigma$ is the input/output alphabet and
$\Sigma \cap \set{\blank} = \emptyset$. It is frequent in literature to relax
this definition, and let $\Gamma \supseteq \Sigma \cup \set{\blank}$.

A larger tape alphabet permits more eloquent work with the tape, where e.g. the
tape alphabet could be extended with a particularly decorated version of the
input/output alphabet. This is useful when e.g. showing that a one-tape Turing
machine is equivalent in computational power to a multi-tape Turing machine.

In a vein similar to Turing machines where the tape head can stay, we can
simulate a machine where

\subsection{Multiple halting states}

\subsection{Multiway and multiple tapes}

\section{Major variants}

Major variants differ from minor variants in that they tend to play a major
role in the theory of computability and complexity.

\begin{itemize}

\item Nondeterministic Turing machines.

\item Enumerators.

\end{itemize}

\section{Church-Turing thesis}

\begin{notion} A \textbf{computational model} is a formal or informal
specification of a means of computation.\end{notion}

For instance, computation by means of Turing machine, as formally defined
above, forms one particular computational model. Other computational models
include various other machine models, and a vast array of conceivable
programming languages, among others.

It is natural to ask whether any of these computational models are any more
powerful, in terms of what they can compute, than a Turing machine. The
Church-Turing thesis conjectures that this is false.

\begin{hypothesis} \textit{(Church-Turing thesis.)}

No computational model can compute anything a Turing machine cannot compute.

\end{hypothesis}

The Church-Turing thesis does not lend itself to mathematical proof. Rather, it
is a proposed explanation for the natural phenomena of computation. The
hypothesis remains to be falsified, and in the mean-while, computational models
more convenient than the Turing machine have emerged, some of them, even useful
in practice.

Some of these models are formally specified, and so it lends itself to formal
proof to show that these models compute no more (or no less) than a Turing
machine does. This is done by showing that one model can simulate the other.

\begin{definition} A computational model is \textbf{Turing complete} if it can
simulate a \textbf{universal Turing machine}. That is, if it can simulate a
machine that given a representation of a Turing machine $M$, and an input $s
\in \Sigma^*$, yields a representation of $t \in \Sigma^*$, such that
$M\p{s}\downarrow t$, and does not halt otherwise. \end{definition}

The proof in the other direction (that a Turing machine can simulate the
computational model) is often omitted, in belief of the Church-Turing thesis.

A proof of the Turing completeness of a computational model, says something
about the class of problems that can be solved within the computational model.
Indeed, it would hereby include (at least) all the problems that can be solved
with a Turing machine. This class of problems may prove too large for practical
purposes, and so we might seek to constrain our computational model.  This is
the subject matter of the subsequent chapters.

Our belief in the Church-Turing thesis also has a notational advantage: to show
that a problem is computable, it is sufficient to informally describe an
algorithm for solving the problem. By the Church-Turing thesis, any
formalisation of the informal algorithm, will yield a computable algorithm.
This is also called presenting the ``pseudo-code'' of the algorithm. Of course,
we have to take care not to employ an overly extravagant step in our
pseudo-code, having no formalisation as a computable step.

Many computational models in use today lack a formal specification. Formally
speaking, they are no more reliable than pseudo-code. The use of formal methods
is often rather cumbersome, and the Church-Turing thesis permits this kind of
leeway in practice.

\section{What does a Turing machine compute?}\label{sec:background-what-tm-computes}

The introduction to this chapter talked about ``solving problems''. We went on
to define computation by means of a Turing machine.

We now characterise what it is that a Turing machine computes, in terms of our
mathematical foundations. In effect, we both give a definition of what we mean
by a ``problem'', and give a ``machine-independent'' characterisation of
computation\footnote{That is, if we don't regard our mathematical foundations
as a machine.}.

Consider a TM $M$. Given a particular input $s\in\Sigma^*$ on tape, $M$ either
halts with the output $t\in\Sigma^*$ on tape, written $M\p{s}\downarrow t$, or
$M$ does not halt, written $M\p{s}\uparrow$. Let
$\Sigma^\downarrow=\set{s\in\Sigma^* \st{\text{$M\p{s}\downarrow t$ for some
$t\in\Sigma^*$}} }$, and let
$\Sigma^\uparrow=\set{s\in\Sigma^*\st{M\p{s}\uparrow}}$.

We can say that $\Sigma^\downarrow$ forms the \emph{domain of definition} of a
partial function $f : \Sigma^* \rightharpoonup \Sigma^*$, which $M$
\emph{implements}, letting $f\p{s}$ be \emph{undefined} for all $s\in
\Sigma^\uparrow$.  That is, the value of $f$ is undefined at $s$ iff $M$ does
not halt on input $s$. We say that $M$ \textbf{computes} the partial function
$f : \Sigma^* \rightharpoonup \Sigma^*$.

\begin{definition} A TM $M$ \textbf{computes} a partial function $f : \Sigma^*
\rightharpoonup \Sigma^*$. \end{definition}

To convince ourselves that $M$ indeed implements a partial function $f :
\Sigma^* \rightharpoonup \Sigma^*$, it remains to show that $M$ implements a
total function $g : \Sigma^\downarrow \rightarrow \Sigma^*$. We consider the
constituents of \refSpec{function} in order:

\begin{enumerate}

\item [F-1] Recall that $\Sigma^\downarrow \subseteq \Sigma^*$. We have that
$S^\downarrow$ and $\Sigma^*$ are sets by definition.

\item [F-2] For each $s\in \Sigma^\downarrow$, $M$ does halt with an output
$t\in\Sigma^*$ on tape.

\item [F-3] The transition function $\delta$ is deterministic, in the sense
that the same input $s \in \Sigma^\downarrow$ will yield the same output $t \in
\Sigma^*$.

\item [F-4] The output $t \in \Sigma^*$ corresponding to each input $s \in
\Sigma^\downarrow$ is completely determined by $M$.

\item [F-5] If we know the sets $S'$ and $\Sigma^*$, and for each $s \in
\Sigma^\downarrow$, the $t \in \Sigma^*$, we can define a TM $M$ that computes
a function $f : \Sigma^\downarrow \rightarrow \Sigma^*$.

\end{enumerate}

If two Turing machines share a tape alphabet, the output of one can serve as
the input to the other. In other words, we can construct a Turing machine that
computes the composite of the respective partial functions.

\begin{theorem} If a Turing machine $M_f$ computes a partial function $f :
\Sigma^* \rightharpoonup \Sigma^*$, and a Turing machine $M_g$ computes a
partial function $g : \Sigma^* \rightharpoonup \Sigma^*$, we can construct a
Turing machine $M_{g \circ f}$, which computes the partial function $\p{g \circ
f} : \Sigma^* \rightharpoonup \Sigma^*$. \end{theorem}

\begin{proof} Let $M_f=\p{Q_f,\qstart^f,\qhalt^f,\Gamma,\delta_f}$, and let
$M_g=\p{Q_g,\qstart^g,\qhalt^g,\Gamma,\delta_g}$. Without loss of generality,
let $Q_f \cap Q_g = \set{\qhalt^f} = \set{\qstart^g}$, that is,
$\qhalt^f=\qstart^g$. Let $Q=Q_f \cup Q_g$, and let $\delta : Q \setminus
\set{\qhalt^g} \times \Gamma \rightarrow Q \times \Gamma \times \set{\goleft,\goright}$ be
defined as follows:

$$\delta\p{q,s}\triangleq\left\{
\begin{array}{l l}
\delta_f\p{q,s} & \text{if $q\in Q_f$} \\
\delta_s\p{q,s} & \text{otherwise}
\end{array}
\right.$$

Let $M_{g \circ f} = \p{Q, \qstart^f, \qhalt^g, \Gamma,
\delta}$.\end{proof}

We can now parley about our algorithms by the compositions of the partial
functions that our Turing machines compute, rather than resort to talking about
the Turing machines themselves.

Although this characterisation may be sufficient for proofs in computability
theory, it provides little comfort for the eloquent programmer. We seek a
slightly more ``abstract'' characterisation of what it is a TM computes.

We note that $\Sigma^*$ is a countably infinite set. This means that for any $s
\in S$, for some countably infinite set $S$, there is a \textbf{unique
representation} of $s$ in $\Sigma^*$. This permits an initial (mental)
abstraction that a Turing machine computes a partial function between a pair of
countably infinite sets.

\begin{theorem} \label{thm:tm-countably-infinite} A TM \textbf{computes} a
partial function $f : S \rightharpoonup T$, for some countably infinite sets
$S$ and $T$.\end{theorem}

\begin{proof} Without loss of generality, let a TM $M$ compute the partial
function $h : \Sigma^* \rightharpoonup \Sigma^*$. By
\refThm{kleene-star-countably-infinite}, $\Sigma^*$ is countably infinite. By
\refThm{countably-infinite-to-countably-infinite}, there exist bijective
functions $i : S \rightarrow \Sigma^*$ and $g : \Sigma^* \rightarrow T$.  Let
$f \triangleq \p{g \circ \p{h \circ i}}$.\end{proof}

\begin{remark} We have now completely dropped the components of a TM from the
characterisation of what it is a TM computes, attaining hereby a
``machine-independent'' characterisation of computation.
\end{remark}

What's more, our mathematical foundations now discourage us from feeding a
natural number to a machine that expects a string as input. Whereas before,
there was no (mental) distinction between e.g. the natural numbers and strings.
Thus, we have introduced the notion of \textbf{types}.

This characterisation is still a little disappointing as the ``types'' we have
at our disposal are rather large. There are, in fact, (countably) infinitely
many values of each type. Some useful, intuitively computable functions work
with a much smaller range of values, e.g. the basic operators of boolean logic
work exclusively with the values \strue{} and \sfalse{}.

To this end, it is easy to exploit both the partiality of the function that a
TM computes and our mathematical foundations:

\begin{theorem} \label{thm:tm-total} A TM \textbf{computes} a total function $f
: S \rightarrow T$, for some countable or countably infinite sets $S$ and $T$.
\end{theorem}

\begin{proof} By \refThm{tm-countably-infinite}, a TM computes a partial
function $g : U \rightharpoonup V$, for some countably infinite sets $U$ and
$V$. Without loss of generality, let $X \subseteq U$ be the domain of
definition of $g$, and let $Y \subseteq V$ be the image. By
\refSpec{partial-function}, the TM computes the (total) function $i : X
\rightarrow Y$.

By \refThm{subset-of-countably-infinite}, $X$ and $Y$ must be countable or
countably infinite. Without loss of generality, let $\card{X}=\card{S}$ and let
$\card{Y}\leq\card{T}$. By \refDef{same-card}, there is a bijective function $j
: S \rightarrow X$. By \refDef{leq-card}, there is an injective function $h : Y
\rightarrow T$. Let $f \triangleq \p{h \circ \p{i \circ j}}$.\end{proof}

The pitfall of \refThm{tm-total} is the (sometimes) unreasonable requirement
that we know the total function of the partial function that a TM computes.
It is a well known uncomputable problem, to pick just those $s \in \Sigma^*$
for which an arbitrary TM $M$ halts with some output $t \in \Sigma^*$.

% and hereby lift the design of programming languages off the ground.

It is the subject matter of much Computer Science, as well as the subsequent
chapters, to limit eloquent programmers to talk just in terms of the
composition of particular (total) functions, which we know are computable.

This motion, has so far, been adjourned. Most general purpose computational
models today relax the termination requirement, and simply permit their
programmers to talk in terms of the composition of particular partial functions
of the form $f : S \rightharpoonup T$, for some countable or countably infinite
sets $S$ and $T$. Informally, $f$ takes a value of some type $S$ as input, and
yields a value of some type $T$ as output, \emph{if} $f$ ever yields a value.
This demands a relaxation of what it is a Turing machine computes.

\begin{theorem} \label{thm:tm-partial} A TM \textbf{computes} a partial
function $f : S \rightharpoonup T$, for some countable or countably infinite
sets $S$ and $T$.\end{theorem}

\begin{proof} By \refThm{tm-total}, a TM computes a total function $i : U
\rightarrow V$ for some countable or countably infinite sets $U$ and $V$.
Without loss of generality, let $\card{S}\leq\card{U}$, and let
$\card{V}\leq\card{T}$. By \refDef{leq-card}, we have an injective function $j
: S \rightarrow U$, and an injective function $h : V \rightarrow T$. Let
$g=\p{h \circ \p{i \circ j}}$. We have $g : S \rightarrow T$. By
\refThm{total-has-partial}, there is a partial function $f : S \rightharpoonup
T$.\end{proof}

We state the following definitions for completeness:

\begin{definition} A partial function $f : S \rightharpoonup T$ is
\textbf{recursively enumerable} if there exists a TM that computes it.
\end{definition}

\begin{definition} A (total) function $f : S \rightarrow T$ is
\textbf{recursive} if there exists a TM that computes it. \end{definition}

Notably, we make no statement about the domain and codomain of a recursively
enumerable or recursive function. These classical definitions.
\refThm{tm-total} and \refThm{tm-partial} seek instead to give a
machine-independent characterisation of what it is a Turing machine computes,
permitting us to lift the machine-independent characterisations of other
computational models off the ground.

%\section{Some uncomputable problems}
