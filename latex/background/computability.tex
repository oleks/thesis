\chapter{Computability} \label{sec:background-computability}

\begin{quotation}

\footnotesize\sffamily\itshape

\begin{flushright}

The ``computable'' numbers may be described briefly as the real numbers whose
expressions as a decimal are calculable by finite means.

\smallbreak

\upshape

--- ALAN TURING, {\itshape Proceedings of The London Mathematical Society} (1936-7)

\end{flushright}

\end{quotation}

The theory of computability is concerned with the nature of computation. It
originated in the 1930s with the celebrated works of G\"odel, Kleene, Church,
Post, Turing, et al.  Fundamental to the field is the Church-Turing thesis,
which proposes that the natural phenomena of computation is captured by the
notion of computation with a Turing machine.

We begin with a brief discussion about the intuitive notion of computation,
leading way for a formal\footnote{By ``formal'', in this chapter and the next,
we mean built atop the mathematical foundations as outlined in
\refSection{preface:mathematical-foundations}. It is an interesting thesis in
its own right to consider an exposition of computability and complexity theory
as based solely on the Church-Turing thesis as an axiom. Some work in this
direction appears in \cite{markov-1954}.} definition of computation with a
Turing machine, and an exposition of the Church-Turing thesis.

\begin{notion} A problem is ``computable'' if it can be solved by transforming
a mathematical object, without ingenuity.
\end{notion}

Any attempt at a more definite notion of computability seems to arrive at a
philosophical impasse, where the notions of ``mathematical object'',
``transformation'', and ``ingenuity'' form a philosophical conundrum. The
indefinite notion however, is sufficient to state the following hypothesis:

\begin{hypothesis} \label{ths:problem-composition} If a problem $P$ can be
solved by solving a computable problem $Q$, immediately followed by solving a
computable problem $R$, then $P$ itself is computable. \end{hypothesis}

The hypothesis clearly holds as nothing is done other than solve the two
computable problems\footnote{Although, doing nothing, is itself a philosophical
conundrum.}.  So any problem which can be solved by solving a finite sequence
of computable problems, is itself computable. We now arrive at an intuitive
notion of an algorithm:

\begin{notion} \label{ntn:problem-algorithm} An ``algorithm'' is a
specification of how a problem can be solved by solving a finite sequence of
computable problems, called ``steps''.\end{notion}

Such indefinite notions are useful for little else. We are left to fall prey to
some choice of formalism. To this end, the notion of computation with a Turing
machine, due to Alan Turing\cite{turing-1936-7}, forms perhaps the most
classical conceptualization of computation. The conceptualization below is
heavily inspired by the those that appear in \cite{tourlakis-1984},
\cite{jones-1997}, \cite{homer-selman-2011}, and \cite{sipser-2013}, but
slightly differs from all of them.

A \textbf{Turing machine} is a symbol-manipulating machine, working with a
1-dimensional, unbounded tape divided into discrete, equally sized squares.
Each square is occupied by a symbol drawn from the \textbf{tape alphabet} of
the machine.  The tape alphabet consists of the \textbf{input/output alphabet},
usually denoted $\Sigma$, and a special \textbf{blank symbol}, written \blank,
which is not in $\Sigma$. The tape has a left edge, but extends into infinity
to the right, filled with blank symbols.

% Inspired by
% http://tex.stackexchange.com/questions/203257/tikz-chains-with-one-side-of-the-leftmost-node-thickbold

\begin{figure}[h!]
\centering
\begin{tikzpicture}
  \tikzset{tape/.style={minimum size=.7cm, draw}}
  \begin{scope}[start chain=0 going right, node distance=0mm]
   \foreach \x [count=\i] in {\symb{1}, \symb{0}, \symb{1}, \symb{0}, \symb{1}, \symb{0}, \blank, \blank, \blank} {
    \ifnum\i=9 % if last node reset outer sep to 0pt
      \node [on chain=0, tape, outer sep=0pt] (n\i) {\x};
      \draw (n\i.north east) -- ++(.1,0) decorate [decoration={zigzag, segment length=.12cm, amplitude=.02cm}] {-- ($(n\i.south east)+(+.1,0)$)} -- (n\i.south east) -- cycle;
     \else
      \node [on chain=0, tape] (n\i) {\x};
     \fi
   }
   \node [right=.25cm of n9] {$\cdots$};
  \end{scope}
\end{tikzpicture}
\caption[]{Schematic of a Turing tape with $\Sigma=\set{\symb{0},\symb{1}}$.}
\label{fig:turing-tape}
\end{figure}

A Turing machine is always in one of a finite, nonempty set of \textbf{states},
also called the \textbf{state alphabet}, and has a tape head, always
overlooking a particular square on the tape. A Turing machine ``computes'' by
transitioning between states and working with the tape head.

The transition from one state to the next is uniquely determined by the current
state, and the symbol read off the overlooked square. A state transition bears
with it writing a new symbol to the overlooked square, and moving the tape head
one square to the left, or one square to the right.

There are two distinguished states, the \textbf{starting state}, usually
denoted \qstart, and the \textbf{halting state}, usually denoted \qhalt. A
Turing machine \textbf{starts} a computation by entering the state \qstart,
overlooking the square at the left end of the tape. A Turing machine
\textbf{halts}, i.e.  performs no further state transitions, if it ever
transitions to the state \qhalt. A halting computation is a finite sequence of
state transitions.

We now formalise these notions as follows:

\begin{definition} A Turing machine (TM) $M$ is a 5-tuple $\p{Q, \qstart,
\qhalt, \Gamma, \delta}$, where

\begin{enumerate}

\item $Q$ is the state alphabet,

\item $\qstart \in Q$ is the starting state,

\item $\qhalt \in Q$ is the halting state,

\item $\Gamma = \Sigma \cup \set{\blank}$ is the tape alphabet, where $\Sigma$
is the input/output alphabet, and $\Sigma \cap \set{\blank} = \emptyset$

\item $\delta : Q \setminus \set{\qhalt} \times \Gamma \rightarrow Q \times
\Gamma \times \set{\symb{L}, \symb{R}}$ is the (total) transition function.

\end{enumerate}

We will omit stating the components of a TM, when they are clear from context.

\end{definition}

\begin{definition} An $M$-\textbf{configuration} of a TM $M$, is a 3-tuple,
written $uqv$, where $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$. If
$v=\varepsilon$, it can be regarded as if $v=\blank$. \end{definition}

We will omit stating that $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$ when
this is clear from context. The additional permission to regard an empty $v$ as
a $v$ containing a blank symbol facilitates the notion of an infinite tape.
This is illustrated by an example further below.

\begin{definition} An $M$-configuration $C_x$ \textbf{yields} an
$M$-configuration $C_y$, written $C_x\leadsto C_y$, iff either

\begin{enumerate}

\item $\delta\p{q_x,a}=\p{q_y,b,\goright}$, $C_x=uq_xav$, and $C_y=ubq_yv$,

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=ucq_xav$, and $C_y=uq_ycbv$,
or

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=q_xbv$,  and $C_y=q_ybv$;

where $a,b,c\in\Sigma$, and $q_x,q_y\in Q$.

\end{enumerate}

\end{definition}

\begin{definition}

A TM $M$ halts with output $y\in\Sigma^*$ on input $x\in\Sigma^*$, written
$M\p{x}\downarrow y$, iff there exists a finite sequence of $M$-configurations,
$\chev{C_1,C_2,\ldots, C_k}$, of length $k\in\mathbb{N}$, such that

\begin{enumerate}

\item $C_1=\qstart x$,

\item $C_i\leadsto C_{i+1}$ for all $1\leq i < k$,

\item $C_k=u\qhalt yv$.

\end{enumerate}

\end{definition}

Note, in particular that the ``tape'' of a TM in such a formalisation is not
infinite, and rather, finite but extensible. As an example, consider a TM $M$,
where $\Sigma=\set{\symb{\#}}$ and $\delta\p{\qstart, \blank} =
\p{\qhalt,\#,\goleft}$. We have that $\qstart\leadsto\qhalt\#$ and
$M\p{}\downarrow\#$.

\section{Minor variants}

In this section, we give some justification for our definition of Turing
machines by considering how it can simulate various variants often found in the
literature. The ability of our Turing machines to simulate these variants
builds confidence in our definition, and permits us to stand on the shoulders
of giants, and state the Church-Turing thesis based on our notion of Turing
machines.

\subsection{Don't move the tape head}

In our definition of a Turing machine, each transition bore with it the
movement of the tape head either left or right. Some variants will also permit
the tape head to stay where it is. 

Our machines can simulate such machines by having two state transitions, first
moving left, then right whenever we wish to simulate a state transition where
the tape head does not move.

\subsection{A larger tape alphabet}

In our definition of a Turing machine we defined the tape alphabet as $\Gamma =
\Sigma \cup \set{\blank}$, where $\Sigma$ is the input/output alphabet and
$\Sigma \cap \set{\blank} = \emptyset$. It is frequent in literature to relax
this definition, and let $\Gamma \supseteq \Sigma \cup \set{\blank}$.

A larger tape alphabet permits more eloquent work with the tape, where e.g. the
tape alphabet could be extended with a particularly decorated version of the
input/output alphabet. This is useful when e.g. showing that a one-tape Turing
machine is equivalent in computational power to a multi-tape Turing machine.

In a vein similar to Turing machines where the tape head can stay, we can
simulate a machine where

\subsection{Multiple halting states}

\subsection{Multiway and multiple tapes}

\section{Major variants}

Major variants differ from minor variants in that they tend to play a major
role in the theory of computability and complexity.

\begin{itemize}

\item Nondeterministic Turing machines.

\item Enumerators.

\end{itemize}

\section{What does a Turing machine compute?}\label{sec:background-what-tm-computes}

The introduction to this chapter talked about ``problems'' being computable. We
went on to define computation by means of a Turing machine. We now formally
discuss what it is that a Turing machine computes, effectively giving a
definition of what we mean by the notion of a ``problem''.

Consider a TM $M$. Given a particular input $s\in\Sigma^*$ on tape, $M$ either
halts with the output $t\in\Sigma^*$ on tape, written $M\p{s}\downarrow t$, or
$M$ does not halt, written $M\p{s}\uparrow$. Let
$S^\downarrow=\set{s\in\Sigma^* \st{\text{$M\p{s}\downarrow t$ for some
$t\in\Sigma^*$}} }$, and let
$S^\uparrow=\set{s\in\Sigma^*\st{M\p{s}\uparrow}}$.

We can say that $S^\downarrow$ forms the \emph{domain of definition} of a
partial function $f_\bot : \Sigma^* \rightharpoonup \Sigma^*$, which $M$
\emph{implements}, letting $f_\bot\p{s}$ be \emph{undefined} for all $s\in
S^\uparrow$.  That is, the value of $f_\bot$ is undefined at $s$ iff $M$ does
not halt on input $s$.

We say that $M$ \textbf{computes} $f_\bot$.

\begin{definition} A TM $M$ computes a partial function $f_\bot : \Sigma^*
\rightharpoonup \Sigma^*$. \end{definition}

To convince ourselves that a TM $M$ indeed implements a partial function
$f_\bot : \Sigma^* \rightharpoonup \Sigma^*$, we need to show that $M$
implements a total function $f:S^\downarrow \rightarrow \Sigma^*$. We consider
the constituents of \refSpec{function} in order:

\begin{enumerate}

\item [F-1] Recall that $S^\downarrow \subseteq \Sigma^*$. We have that
$S^\downarrow$ and $\Sigma^*$ are sets by definition.

\item [F-2] For each $s\in S^\downarrow$, $M$ does halt with an output
$t\in\Sigma^*$ on tape.

\item [F-3] The transition function $\delta$ is
deterministic, in the sense that the same input $s\in S^\downarrow$ will yield
the same output $t\in\Sigma^*$.

\item [F-4] The output $t\in\Sigma^*$ corresponding to each input $s\in S'$ is
completely determined by $M$.

\item [F-5] If we know the sets $S'$ and $\Sigma^*$, and for each $s\in S'$,
the $t\in \Sigma^*$, we can define a TM $M$ that computes a function
$f:S'\rightarrow \Sigma^*$.

\end{enumerate}

Although this characterisation of what it is a TM computes may be sufficient
for proofs in computability theory, it is of little comfort to the eloquent
programmer. This is to be expected, as Turing machines were not designed for
eloquent programming. We can, never-the-less, provide a slightly more
``abstract'' characterisation of TM computation. For this, we will need a bit
of abstraction machinery:

% and hereby lift the design of programming languages off the ground.

\begin{theorem}\label{thm:unique-representation} For any countable set $S$, and
alphabet $\Sigma$, for each $s\in S$ there is a \textbf{unique representation}
of $s$ in $\Sigma^*$, written $\overline{s}\in\Sigma^*$. That is, there is a
bijective function $e : S \rightarrow T$, for some $T \subseteq \Sigma^*$.
\end{theorem}

% a partial function $d_\bot : \Sigma^* \rightharpoonup S$ with the domain of
% definition $T$.

\begin{proof} By \refDef{countable}, we have an injective function $f : S
\rightarrow \mathbb{N}$. By \refThm{kleene-star-countably-infinite}, $\Sigma^*$
is countably infinite. By \refDef{countably-infinite} and \refDef{bijective},
we have a bijective function $g:\mathbb{N}\rightarrow\Sigma^*$. Let $h = g\circ
f$. By ... $h : S\rightarrow \Sigma^*$ is an injective function. 

Let $T=h\seq{S}$ be the image of $h$. By \refDef{image}, $T \subseteq
\Sigma^*$. Since $h$ is injective, we must have $\card{S}=\card{T}$. Then, by
\refDef{same-card}, there must be a bijective function $e : S \rightarrow
T$.\end{proof}

By \refDef{tm-computes-sigma} and \refThm{unique-representation}, we can now
say more generally, that a Turing machine computes a function $f:X\rightarrow
\Sigma^*$, for some countable set $X$. This is better, but a little
disappointing. It is a bit like saying if you throw in the ingredients of a
cake, we promise to deliver you a string of symbols drawn from $\Sigma$, if
anything. Recall that $\Sigma^*$ is a countably infinite set. This leads to the
slightly more general characterisation of what it is that a TM computes.

If two Turing machines share a tape alphabet, the output of one Turing machine
can serve as the input to another.

This can be modelled by the composition of the
partial functions that the TMs compute.

\begin{definition} If a TM $M_f$ computes a partial function $f_\bot : \Sigma^*
\rightharpoonup \Sigma^*$, and a TM $M_g$ computes a partial function $g_\bot :
\Sigma^* \rightharpoonup \Sigma^*$, then the composite TM $M_{g\circ f}$
computes the composite partial function $\p{g_\bot \circ f_\bot} : \Sigma^*
\rightharpoonup \Sigma^*$, such that $M_{g_\bot \circ f_\bot}\p{v}\downarrow w$
for all $v\in S_f$, where $f\p{v}\in S_g$, and $M_{g_\bot \circ
f_\bot}\p{v}\uparrow$ otherwise. \end{definition}

\begin{theorem} If a TM $M_1$ computes a function $f : \Sigma^* \rightarrow
\Sigma^*_\bot$, and a TM $M_2$ computes a function $g : \Sigma^* \rightarrow
\Sigma^*_\bot$, then there exists a TM $M$ which computes the function $g\circ
f : \Sigma^* \rightarrow \Sigma^*_\bot$.\end{theorem}

\begin{proof} Proof by pseudo code. \end{proof}

We can now parley about our algorithms by the compositions of functions that
our Turing machines compute, rather than resort to talking about the Turing
machines themselves.

This is still a little disappointing. A countably infinite set is ``no
smaller'' than $\Sigma^*$. We can now throw in the ingredients of a cake, and
be guaranteed only to get \emph{some} cake, if anything at all. We are not
guaranteed to get a cake, and certainly not guaranteed to get the cake we want.

It is perhaps worthwhile to reconsider representing functions as sets. If for a
given TM $M$, we could construct the set of pairs
$\set{\p{x,y}\st{\text{$M\p{x}\downarrow y$ or $y=\bot$}}}$, the second
components of the pairs uniquely determine the codomain of the function
computed by $M$. As we shall later prove, deciding whether a Turing machine
halts or not, is ``undecidable'' in general, and so unfortunately, this is not
an option.

It is the subject matter of much Computer Science, and likewise the remainder
of this thesis, to consider limiting the programmers to talk just in terms of
composing particular functions, for which the codomains (among other
properties) are either known beforehand, or can be determined by finite means.
Hopefully, we can then be guaranteed, that if we throw in the right
ingredients, without too much hassle, we will be delivered just the cake we
want, in time for lunch.

\begin{lemma} \label{lem:tm-domain} For any partial function $f : T
\rightharpoonup U$, where $T$ is a countably infinite set, and any countable or
countably infinite set $S$, there is a partial function $h : S \rightharpoonup
U$. \end{lemma}

\begin{proof} We show that there is an injective function $g : S \rightarrow
T$, and let $h \triangleq \p{f \circ g}$. If $S$ is countable, then by
\refThm{countable-to-countably-infinite} there is an injective function $g : S
\rightarrow T$. If $S$ is countably infinite, then by
\refThm{countably-infinite-to-countably-infinite} there is a bijective function
$g : S \rightarrow T$, which by \refDef{bijective} is also
injective.\end{proof}

\begin{lemma} \label{lem:tm-codomain} For any partial function $f : S
\rightharpoonup T$, where $T$ is a countably infinite set, and any countable or
countably infinite set $U$, there is a partial function $h : S \rightharpoonup
U$. \end{lemma}

\begin{proof} We show that there is a surjective function $g : T
\rightharpoonup U$, and let $h \triangleq \p{g \circ f}$. \end{proof}

\begin{theorem} \label{thm:tm-machine-independent} A TM computes a partial
function $f : S \rightharpoonup T$, for some countable, or countably infinite
sets $S$ and $T$. \end{theorem}

\begin{proof} Let $\Sigma$ be the alphabet of some Turing machine $M$ ...
Without loss of generality, let $M$ compute the partial function $h : \Sigma^*
\rightharpoonup \Sigma^*$.  \end{proof} 

\begin{remark} We have now completely dropped the components of a TM from the
characterisation of the function that the TM computes, attaining hereby a
``machine-independent characterisation'' of what it is that the TM computes.
\end{remark}

An unsatisfying aspect of this characterisation, from a natural point of view,
is that we do not know the domain of definition of the partial function $f : S
\rightharpoonup T$ that a TM computes. As we shall later prove, it is not
possible in general, to deduce such a domain of definition from a TM.

\section{Church-Turing thesis}

\begin{hypothesis} \textit{(Church-Turing thesis.)}

No intuitive notion of an algorithm can compute a function that a Turing
machine cannot compute.

\end{hypothesis}

The Church-Turing thesis does not lend itself to mathematical proof. Rather, it
is a proposed explanation of the natural phenomena of computation. The
hypothesis remains to be disproven, and in the mean-while, computational models
more convenient than the Turing machine have emerged, some of them, even useful
in practice.

Some of these models have a formal specification, and so it lends itself to
formal proof that these models compute no more than a Turing machine does.

Our belief in the Church-Turing thesis has however, a notational advantage: to
show that a function $f$ is computable, it is sufficient to informally
describe, an algorithm for computing $f$. Due to the hypothesis, any
formalisation of the informal algorithm, will yield a computable algorithm,

This is sometimes called providing the ``pseudo-code'' for computing $f$, but can be said
of most ``code'' today in general.

Formal methods, due to their inherent complexity are seldom employed.


\subsection{Recursively enumerable and recursive functions}

\begin{definition} The partial function $f:X\rightarrow Y_\bot$ is said to be
\textbf{recursively enumerable} if some TM computes it. \end{definition}

\begin{definition} The (total) function $f:X\rightarrow Y$ is said to be
\textbf{recursive} if some TM computes it. \end{definition}

\section{Some uncomputable problems}
