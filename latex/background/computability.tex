\chapter{Computability} \label{sec:background-computability}

\begin{quotation}

\footnotesize\sffamily\itshape

\begin{flushright}

The ``computable'' numbers may be described briefly as the real numbers whose
expressions as a decimal are calculable by finite means.

\smallbreak

\upshape

--- ALAN TURING, {\itshape Proceedings of The London Mathematical Society} (1936-7)

\end{flushright}

\end{quotation}

The theory of computability is concerned with the nature of computation. It
originated in the 1930s with the celebrated works of G\"odel, Kleene, Church,
Post, Turing, et al.  Fundamental to the field is the Church-Turing thesis,
which proposes that the natural phenomena of computation is captured by the
definition of computation with a Turing machine.

We begin with a brief discussion about the intuitive notion of computation,
leading way for a formal\footnote{By ``formal'', in this chapter and the next,
we mean built atop the mathematical foundations as outlined in
\refSection{preface:mathematical-foundations}. It is an interesting thesis in
its own right to consider an exposition of computability and complexity theory
as based solely on the Church-Turing thesis as an axiom. Some work in this
direction appears in \cite{markov-1954}.} definition of computation with a
Turing machine, culminating in an exposition of the Church-Turing thesis.

\section{Notion of computation}

\begin{notion} A problem is ``computable'' if it can be solved by transforming
a mathematical object, without ingenuity. \end{notion}

Any attempt at a more definite notion of computation seems to arrive at a
philosophical impasse, where the notions of ``mathematical object'',
``transformation'', and ``ingenuity'' form a philosophical conundrum. The
indefinite notion however, is perhaps sufficient to state a couple hyptheses
about the nature of computation:

\begin{hypothesis} \label{ths:do-nothing} Doing nothing is computable.
\end{hypothesis}

\begin{hypothesis} \label{ths:problem-composition} If a problem $P$ can be
solved by solving a computable problem $Q$, immediately followed by solving a
computable problem $R$, then $P$ itself is computable. \end{hypothesis}

The hypothesis clearly holds as nothing is done other than solve the two
computable problems.  So any problem which can be solved by solving a finite sequence
of computable problems, is itself computable. We now arrive at an intuitive
notion of an algorithm:

\begin{notion} \label{ntn:problem-algorithm} An ``algorithm'' is a
specification of how a problem can be solved by solving a finite sequence of
computable problems, called ``steps''.\end{notion}

The notion of computation yearns perhaps for a category-theoretical definition.
Such a definition however, is both non-classical and somewhat disputed.

Such indefinite notions are useful for little else. We are left to fall prey to
some choice of formalism. 

A problem is ``computable'' if it can be solved by means of computation. That
is, if a mathematical . Assuming a set theoretical foundation of mathematics,
computation induces a function on sets.

Before further characterising the class of computable functions

\section{Turing machines}

To this end, the notion of computation with a Turing
machine, due to Alan Turing\cite{turing-1936-7}, forms perhaps the most
classical conceptualization of computation. The conceptualization below is
heavily inspired by the those that appear in \cite{tourlakis-1984},
\cite{jones-1997}, \cite{homer-selman-2011}, and \cite{sipser-2013}, but
slightly differs from all of them.

A \textbf{Turing machine} is a symbol-manipulating machine, working with a
1-dimensional, unbounded tape divided into discrete, equally sized squares.
Each square is occupied by a symbol drawn from the \textbf{tape alphabet} of
the machine.  The tape alphabet consists of the \textbf{input/output alphabet},
usually denoted $\Sigma$, and a special \textbf{blank symbol}, written \blank,
which is not in $\Sigma$. The tape has a left edge, but extends into infinity
to the right, filled with blank symbols.

% Inspired by
% http://tex.stackexchange.com/questions/203257/tikz-chains-with-one-side-of-the-leftmost-node-thickbold

\begin{figure}[h!]
\centering
\begin{tikzpicture}
  \tikzset{tape/.style={minimum size=.7cm, draw}}
  \begin{scope}[start chain=0 going right, node distance=0mm]
   \foreach \x [count=\i] in {\symb{1}, \symb{0}, \symb{1}, \symb{0}, \symb{1}, \symb{0}, \blank, \blank, \blank} {
    \ifnum\i=9 % if last node reset outer sep to 0pt
      \node [on chain=0, tape, outer sep=0pt] (n\i) {\x};
      \draw (n\i.north east) -- ++(.1,0) decorate [decoration={zigzag, segment length=.12cm, amplitude=.02cm}] {-- ($(n\i.south east)+(+.1,0)$)} -- (n\i.south east) -- cycle;
     \else
      \node [on chain=0, tape] (n\i) {\x};
     \fi
   }
   \node [right=.25cm of n9] {$\cdots$};
  \end{scope}
\end{tikzpicture}
\caption[]{Schematic of a Turing tape with $\Sigma=\set{\symb{0},\symb{1}}$.}
\label{fig:turing-tape}
\end{figure}

A Turing machine is always in one of a finite, nonempty set of \textbf{states},
also called the \textbf{state alphabet}, and has a tape head, always
overlooking a particular square on the tape. A Turing machine ``computes'' by
transitioning between states and working with the tape head.

The transition from one state to the next is uniquely determined by the current
state, and the symbol read off the overlooked square. A state transition bears
with it writing a new symbol to the overlooked square, and moving the tape head
one square to the left, or one square to the right.

There are two distinguished states, the \textbf{starting state}, usually
denoted \qstart, and the \textbf{halting state}, usually denoted \qhalt. A
Turing machine \textbf{starts} a computation by entering the state \qstart,
overlooking the square at the left end of the tape. A Turing machine
\textbf{halts}, i.e.  performs no further state transitions, if it ever
transitions to the state \qhalt. A halting computation is a finite sequence of
state transitions.

We now formalise these notions as follows:

\begin{definition} A Turing machine (TM) $M$ is a 5-tuple $\p{Q, \qstart,
\qhalt, \Gamma, \delta}$, where

\begin{enumerate}

\item $Q$ is the state alphabet,

\item $\qstart \in Q$ is the starting state,

\item $\qhalt \in Q$ is the halting state,

\item $\Gamma = \Sigma \cup \set{\blank}$ is the tape alphabet, where $\Sigma$
is the input/output alphabet, and $\Sigma \cap \set{\blank} = \emptyset$

\item $\delta : Q \setminus \set{\qhalt} \times \Gamma \rightarrow Q \times
\Gamma \times \set{\symb{L}, \symb{R}}$ is the (total) transition function.

\end{enumerate}

We will omit stating the components of a TM, when they are clear from context.

\end{definition}

\begin{definition} An $M$-\textbf{configuration} of a TM $M$, is a 3-tuple,
written $uqv$, where $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$. If
$v=\varepsilon$, it can be regarded as if $v=\blank$. \end{definition}

We will omit stating that $u\in\Gamma^*$, $q\in Q$, and $v\in\Gamma^*$ when
this is clear from context. The additional permission to regard an empty $v$ as
a $v$ containing a blank symbol facilitates the notion of an infinite tape.
This is illustrated by an example further below.

\begin{definition} An $M$-configuration $C_x$ \textbf{yields} an
$M$-configuration $C_y$, written $C_x\leadsto C_y$, iff either

\begin{enumerate}

\item $\delta\p{q_x,a}=\p{q_y,b,\goright}$, $C_x=uq_xav$, and $C_y=ubq_yv$,

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=ucq_xav$, and $C_y=uq_ycbv$,
or

\item $\delta\p{q_x,a}=\p{q_y,b,\goleft}$, $C_x=q_xbv$,  and $C_y=q_ybv$;

where $a,b,c\in\Sigma$, and $q_x,q_y\in Q$.

\end{enumerate}

\end{definition}

\begin{definition}

A TM $M$ halts with output $y\in\Sigma^*$ on input $x\in\Sigma^*$, written
$M\p{x}\downarrow y$, iff there exists a finite sequence of $M$-configurations,
$\chev{C_1,C_2,\ldots, C_k}$, of length $k\in\mathbb{N}$, such that

\begin{enumerate}

\item $C_1=\qstart x$,

\item $C_i\leadsto C_{i+1}$ for all $1\leq i < k$,

\item $C_k=u\qhalt yv$.

\end{enumerate}

\end{definition}

Note, in particular that the ``tape'' of a TM in such a formalisation is not
infinite, and rather, finite but extensible. As an example, consider a TM $M$,
where $\Sigma=\set{\symb{\#}}$ and $\delta\p{\qstart, \blank} =
\p{\qhalt,\#,\goleft}$. We have that $\qstart\leadsto\qhalt\#$ and
$M\p{}\downarrow\#$.

\section{Minor variants}

In this section, we give some justification for our definition of Turing
machines by considering how it can simulate various variants often found in the
literature. The ability of our Turing machines to simulate these variants
builds confidence in our definition, and permits us to stand on the shoulders
of giants, and state the Church-Turing thesis based on our notion of Turing
machines.

\subsection{Don't move the tape head}

In our definition of a Turing machine, each transition bore with it the
movement of the tape head either left or right. Some variants will also permit
the tape head to stay where it is. 

Our machines can simulate such machines by having two state transitions, first
moving left, then right whenever we wish to simulate a state transition where
the tape head does not move.

\subsection{A larger tape alphabet}

In our definition of a Turing machine we defined the tape alphabet as $\Gamma =
\Sigma \cup \set{\blank}$, where $\Sigma$ is the input/output alphabet and
$\Sigma \cap \set{\blank} = \emptyset$. It is frequent in literature to relax
this definition, and let $\Gamma \supseteq \Sigma \cup \set{\blank}$.

A larger tape alphabet permits more eloquent work with the tape, where e.g. the
tape alphabet could be extended with a particularly decorated version of the
input/output alphabet. This is useful when e.g. showing that a one-tape Turing
machine is equivalent in computational power to a multi-tape Turing machine.

In a vein similar to Turing machines where the tape head can stay, we can
simulate a machine where

\subsection{Multiple halting states}

\subsection{Multiway and multiple tapes}

\section{Major variants}

Major variants differ from minor variants in that they tend to play a major
role in the theory of computability and complexity.

\begin{itemize}

\item Nondeterministic Turing machines.

\item Enumerators.

\end{itemize}

\section{What does a Turing machine compute?}\label{sec:background-what-tm-computes}

The introduction to this chapter talked about ``problems'' being computable. We
went on to define computation by means of a Turing machine. We now characterise
what it is that a Turing machine computes, in terms of our mathematical
foundations, effectively giving both a definition of what we mean by the notion
of a ``problem'', and a ``machine-independent'' characterisation of
computation.

Consider a TM $M$. Given a particular input $s\in\Sigma^*$ on tape, $M$ either
halts with the output $t\in\Sigma^*$ on tape, written $M\p{s}\downarrow t$, or
$M$ does not halt, written $M\p{s}\uparrow$. Let
$S^\downarrow=\set{s\in\Sigma^* \st{\text{$M\p{s}\downarrow t$ for some
$t\in\Sigma^*$}} }$, and let
$S^\uparrow=\set{s\in\Sigma^*\st{M\p{s}\uparrow}}$.

We can say that $S^\downarrow$ forms the \emph{domain of definition} of a
partial function $f : \Sigma^* \rightharpoonup \Sigma^*$, which $M$
\emph{implements}, letting $f\p{s}$ be \emph{undefined} for all $s\in
S^\uparrow$.  That is, the value of $f$ is undefined at $s$ iff $M$ does not
halt on input $s$. We say that $M$ \textbf{computes} the partial function $f :
\Sigma^* \rightharpoonup \Sigma^*$.

\begin{definition} A TM $M$ \textbf{computes} a partial function $f : \Sigma^*
\rightharpoonup \Sigma^*$. \end{definition}

To convince ourselves that $M$ indeed implements a partial function $f :
\Sigma^* \rightharpoonup \Sigma^*$, it remains to show that $M$ implements a
total function $g:S^\downarrow \rightarrow \Sigma^*$. We consider the
constituents of \refSpec{function} in order:

\begin{enumerate}

\item [F-1] Recall that $S^\downarrow \subseteq \Sigma^*$. We have that
$S^\downarrow$ and $\Sigma^*$ are sets by definition.

\item [F-2] For each $s\in S^\downarrow$, $M$ does halt with an output
$t\in\Sigma^*$ on tape.

\item [F-3] The transition function $\delta$ is
deterministic, in the sense that the same input $s\in S^\downarrow$ will yield
the same output $t\in\Sigma^*$.

\item [F-4] The output $t\in\Sigma^*$ corresponding to each input $s\in S'$ is
completely determined by $M$.

\item [F-5] If we know the sets $S'$ and $\Sigma^*$, and for each $s\in S'$,
the $t\in \Sigma^*$, we can define a TM $M$ that computes a function
$f:S'\rightarrow \Sigma^*$.

\end{enumerate}

If two Turing machines share a tape alphabet, the output of one can serve as
the input to the other. In other words, we can construct a Turing machine that
computes the composite of the respective partial functions.

\begin{theorem} If a Turing machine $M_f$ computes a partial function $f :
\Sigma^* \rightharpoonup \Sigma^*$, and a Turing machine $M_g$ computes a
partial function $g : \Sigma^* \rightharpoonup \Sigma^*$, we can construct a
Turing machine $M_{g \circ f}$, which computes the partial function $\p{g \circ
f} : \Sigma^* \rightharpoonup \Sigma^*$. \end{theorem}

\begin{proof} Let $M_f=\p{Q_f,\qstart^f,\qhalt^f,\Gamma,\delta_f}$, and let
$M_g=\p{Q_g,\qstart^g,\qhalt^g,\Gamma,\delta_g}$. Without loss of generality,
let $Q_f \cap Q_g = \set{\qhalt^f} = \set{\qstart^g}$, that is,
$\qhalt^f=\qstart^g$. Let $Q=Q_f \cup Q_g$, and let $\delta : Q \setminus
\set{\qhalt^g} \rightarrow Q \times \Gamma \times \set{\goleft,\goright}$ be
defined as follows ... Let $M_{g \circ f} = \p{Q, \qstart^f, \qhalt^g, \Gamma,
\delta}$.\end{proof}

This means that we can parley about our algorithms by the compositions of the
partial functions that our Turing machines compute, rather than resort to
talking about the Turing machines themselves.

Although this characterisation may be sufficient for proofs in computability
theory, it provides little comfort for the eloquent programmer. We seek a
slightly more ``abstract'' characterisation of what it is a TM computes.

We note that $\Sigma^*$ is a countably infinite set. This means that for any $s
\in S$, for some countably infinite set $S$, there is a \textbf{unique
representation} of $s$ in $\Sigma^*$. This permits an initial (mental)
abstraction that a Turing machine computes a partial function between a pair of
countably infinite sets.

\begin{theorem} \label{thm:tm-countably-infinite} A TM \textbf{computes} a
partial function $f : S \rightharpoonup T$, where $S$ and $T$ are countably
infinite sets.  \end{theorem}

\begin{proof} Without loss of generality, let a TM $M$ compute the partial
function $h : \Sigma^* \rightharpoonup \Sigma^*$. By
\refThm{kleene-star-countably-infinite}, $\Sigma^*$ is countably infinite. By
\refThm{countably-infinite-to-countably-infinite}, there exist bijective
functions $i : S \rightarrow \Sigma^*$ and $g : \Sigma^* \rightarrow T$.  Let
$f \triangleq \p{g \circ \p{h \circ i}}$.\end{proof}

\begin{remark} We have now completely dropped the components of a TM from the
characterisation of what it is a TM computes, attaining hereby a
``machine-independent'' characterisation.
\end{remark}

What's more, our mathematical foundations now discourage us from feeding a
natural number to a machine that expects a string as input. Whereas before,
there was no (mental) distinction between e.g. the natural numbers and strings.
Thus, we have introduced the notion of \textbf{types}.

This characterisation is still a little disappointing: the ``types'' we have at
our disposal are rather large. There are, in fact, (countably) infinitely many
values of each type. Some useful, intuitively computable functions work with a
much smaller range of values, e.g. the basic operators of boolean logic work
exclusively with the values \strue{} and \sfalse{}.

To this end, it is easy to exploit both the partiality of the function that a
TM computes and our mathematical foundations:

\begin{theorem} \label{thm:tm-can-compute} A TM \textbf{can compute} a total
function $f : S \rightarrow T$, where $S$ and $T$ are countable or countably
infinite sets. \end{theorem}

\begin{proof} Without loss of generality, let a TM $M$ compute the partial
function $g : \Sigma^* \rightharpoonup \Sigma^*$, with the domain of definition
$U \subseteq \Sigma^*$, and image $V \subseteq \Sigma ^*$. By
\refSpec{partial-function}, $M$ computes the (total) function $i : U
\rightarrow V$.

By \refThm{kleene-star-countably-infinite}, $\Sigma^*$ is countably infinite.
By \refThm{subset-of-countably-infinite}, $U$ and $V$ must be countable or
countably infinite. Without loss of generality, let $\card{U}=\card{S}$ and let
$\card{V}\leq\card{T}$. By \refDef{same-card}, there is a bijective function $j
: S \rightarrow U$. By \refDef{leq-card}, there is an injective function $h : V
\rightarrow T$. Let $f \triangleq \p{h \circ \p{i \circ j}}$.\end{proof}

The change of wording between \refThm{tm-countably-infinite} and
\refThm{tm-can-compute} from ``computes'' to ``can compute'' is intensional. It
serves to signify the (sometimes) unreasonable requirement of the latter
theorem that we know the total function that a TM computes. This requirement is
unreasonable, as it is a well-known undecidable problem to find the domain of
definition, let alone image, of the partial function that a TM computes.

% and hereby lift the design of programming languages off the ground.






If two Turing machines share a tape alphabet, the output of one Turing machine
can serve as the input to another.

This can be modelled by the composition of the
partial functions that the TMs compute.

\begin{theorem} If a TM $M_1$ computes a function $f : \Sigma^* \rightarrow
\Sigma^*_\bot$, and a TM $M_2$ computes a function $g : \Sigma^* \rightarrow
\Sigma^*_\bot$, then there exists a TM $M$ which computes the function $g\circ
f : \Sigma^* \rightarrow \Sigma^*_\bot$.\end{theorem}

\begin{proof} Proof by pseudo code. \end{proof}

We can now parley about our algorithms by the compositions of functions that
our Turing machines compute, rather than resort to talking about the Turing
machines themselves.

This is still a little disappointing. A countably infinite set is ``no
smaller'' than $\Sigma^*$. We can now throw in the ingredients of a cake, and
be guaranteed only to get \emph{some} cake, if anything at all. We are not
guaranteed to get a cake, and certainly not guaranteed to get the cake we want.

It is perhaps worthwhile to reconsider representing functions as sets. If for a
given TM $M$, we could construct the set of pairs
$\set{\p{x,y}\st{\text{$M\p{x}\downarrow y$ or $y=\bot$}}}$, the second
components of the pairs uniquely determine the codomain of the function
computed by $M$. As we shall later prove, deciding whether a Turing machine
halts or not, is ``undecidable'' in general, and so unfortunately, this is not
an option.

It is the subject matter of much Computer Science, and likewise the remainder
of this thesis, to consider limiting the programmers to talk just in terms of
composing particular functions, for which the codomains (among other
properties) are either known beforehand, or can be determined by finite means.
Hopefully, we can then be guaranteed, that if we throw in the right
ingredients, without too much hassle, we will be delivered just the cake we
want, in time for lunch.

\begin{lemma} \label{lem:tm-domain} For any partial function $f : T
\rightharpoonup U$, where $T$ is a countably infinite set, and any countable or
countably infinite set $S$, there is a partial function $h : S \rightharpoonup
U$. \end{lemma}

\begin{proof} We show that there is an injective function $g : S \rightarrow
T$, and let $h \triangleq \p{f \circ g}$. If $S$ is countable, then by
\refThm{countable-to-countably-infinite} there is an injective function $g : S
\rightarrow T$. If $S$ is countably infinite, then by
\refThm{countably-infinite-to-countably-infinite}, there is a bijective
function $g : S \rightarrow T$, which by \refDef{bijective} is also
injective.\end{proof}

\begin{theorem} \label{thm:tm-machine-independent} A TM computes a partial
function $f : S \rightharpoonup T$, for some countable, or countably infinite
sets $S$ and countably infinite set $T$. \end{theorem}

\begin{proof} Without loss of generality, let $M$ compute the partial function
$h : \Sigma^* \rightharpoonup \Sigma^*$. By
\refThm{kleene-star-countably-infinite}, $\Sigma^*$ is countably infinite. Let
$S$ and $T$ be either countable or countably infinite sets. By
\refLem{tm-domain} and \refLem{tm-codomain}, $M$ computes the function $f : S
\rightharpoonup T$. \end{proof}

\begin{remark} We have now completely dropped the components of a TM from the
characterisation of the function that the TM computes, attaining hereby a
``machine-independent characterisation'' of what it is that the TM computes.
\end{remark}

An unsatisfying aspect of this characterisation, from a natural point of view,
is that we do not know the domain of definition of the partial function $f : S
\rightharpoonup T$ that a TM computes. As we shall later prove, it is not
possible in general, to deduce such a domain of definition from a TM.

\begin{lemma} \label{lem:tm-codomain} For any partial function $f : S
\rightharpoonup T$, where $T$ is a countably infinite set, and any countable or
countably infinite set $U$, there is a partial function $h : S \rightharpoonup
U$. \end{lemma}

\begin{proof} We show that there is a surjective \emph{partial} function $g : T
\rightharpoonup U$, and let $h \triangleq \p{g \circ f}$. If $U$ is countable,
then by \refThm{countably-infinite-to-countable}, there is a surjective partial
function $g : T \rightharpoonup U$. If $U$ is countably infinite, then by
\refThm{countably-infinite-to-countably-infinite}, there is a bijective
function $g : T \rightarrow U$, which by \refDef{bijective} is also surjective.
By \refThm{total-has-partial}, we must also have a surjective partial function
$g : T \rightharpoonup U$.\end{proof}


\section{Church-Turing thesis}

Assuming that whatever we may wish to ``compute'' can be characterised by a
mathematical function, we now state the Church-Turing thesis:

\begin{hypothesis} \textit{(Church-Turing thesis.)}

No intuitive notion of an algorithm can compute a function that a Turing
machine cannot compute.

\end{hypothesis}

The Church-Turing thesis does not lend itself to mathematical proof. Rather, it
is a proposed explanation of the natural phenomena of computation. The
hypothesis remains to be falsified, and in the mean-while, computational models
more convenient than the Turing machine have emerged, some of them, even useful
in practice.

Some of these models have a formal specification, and so it lends itself to
formal proof that these models compute no more than a Turing machine does.

Our belief in the Church-Turing thesis has however, a notational advantage: to
show that a function $f$ is computable, it is sufficient to informally
describe, an algorithm for computing $f$. Due to the hypothesis, any
formalisation of the informal algorithm, will yield a computable algorithm,

This is sometimes called providing the ``pseudo-code'' for computing $f$, but can be said
of most ``code'' today in general.

Formal methods, due to their inherent complexity are seldom employed.


\subsection{Recursively enumerable and recursive functions}

\begin{definition} The partial function $f:X\rightarrow Y_\bot$ is said to be
\textbf{recursively enumerable} if some TM computes it. \end{definition}

\begin{definition} The (total) function $f:X\rightarrow Y$ is said to be
\textbf{recursive} if some TM computes it. \end{definition}

\section{Some uncomputable problems}
