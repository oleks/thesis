\chapter{Computability}

\begin{quotation}

\footnotesize\sffamily\itshape

\begin{flushright}

The ``computable'' numbers may be described briefly as the real numbers whose
expressions as a decimal are calculable by finite means.

\smallbreak

\upshape

--- ALAN TURING, {\itshape Proceedings of The London Mathematical Society} (1936-7)

\end{flushright}

\end{quotation}

% Aka. Computability Theory

The theory of computability is a branch of Mathematical Logic and Computer
Science, concerned with the nature of computation. It originated in the 1930s
with the celebrated works of G\"odel, Kleene, Church, Post, Turing, et al.

Fundamental to the science of computability is the Church-Turing thesis, which
proposes that the notion of a Turing machine captures the natural phenomena of
computation. Belief in this thesis permits us to work with the established
notion of a Turing machine to formally develop computational algebras, which
serve to support the fundamental human faculty of computation.

For instance, a computational algebra may more closely resemble the mode of
computation with a particular real-world machine. Such computational algebras
are called ``machine models''. On the other hand, a computational algebra may
enable us to specify a computation in a manner that is clear and concise, and
perhaps even closely resembles our problem domain. Such computational algebras
are called ``programming languages''.

A modern exposition of the field would typically assume some notion of sets,
and some basic set constructions, in the form of functions, Cartesian products,
unions, etc. We choose to take a slightly different route.

The foundations of mathematics, unlike the foundations of computation, remain
largely disputed. This is not to say that computation is somehow superior to
mathematics. Quite the contrary, computation is a natural phenomena, whereas
mathematics is free to roam in the supernatural. For this reason, we develop
the notion of a Turing machine and what it can compute, and take the
Church-Turing thesis to hold as an axiom. This forms the axiomatic foundation
of our computational algebras going forth.

\section{Finite sets}

It is beyond the scope of this thesis to develop the notion of ``finite sets'',
``Cartesian products'', and ``total functions'' over finite sets. We assume
these notions as given, subject to the following specifications:

\begin{specification}

A \textbf{finite set} $X$ is distinct from, but defined by its finite
collection of \textbf{elements}, having the following properties:

\begin{enumerate}

\item The elements of $X$ can be considered in sequence.

\item Two elements of $X$ are either equal to or not.

\end{enumerate}

\end{specification}

We will exemplify and further specify these properties in the following
paragraphs.

\begin{notation} A finite set is given by denoting the elements of the set in a
typographical sequence, separated by commas, and enclosed in braces. For
instance, $X\triangleq\set{\symb{a},\symb{b},\symb{c}}$ defines a finite set
$X$, defined by the elements $\symb{a}$, $\symb{b}$, and
$\symb{c}$.\end{notation}

\begin{notation} An element $x$ of $X$ is written as $x:X$. \end{notation}

We now consider some operations that form new finite sets from given finite sets.

\begin{specification} A \textbf{total function} $f$ over finite sets $X$ and
$Y$, written  $f:X\rightarrow Y$, has ``domain'' $X$ and ``codomain'' $Y$,
and adheres to the following properties:

\begin{enumerate}

\item For each $x:X$, $f$ has a \textbf{value} at $x$ in $Y$, written $f\p{x}:Y$.

\item $X$, $Y$, and $f\p{x} : Y$ for each $x : X$, are all determined completely
by $f$.

\item $X$, $Y$, and $f\p{x} : Y$ for each $x : X$, completely determine $f$.

\end{enumerate}

\end{specification}

\begin{specification} The \textbf{Cartesian product} over finite sets $X$ and
$Y$, written $X\times Y$, is the finite set of all pairs, written $\p{x,y}$,
where $x:X$ and $y:Y$. \end{specification}

\begin{alias} An \textbf{alphabet} is a finite set of \textbf{symbols}.
\end{alias}

\pagebreak

We begin with a brief discussion about the intuitive notion of computation.
This will motivate our choice of mathematical foundations, enabling a formal
definition of a model of computation with Turing machines. We conclude with an
exposition of the Church-Turing thesis, which hypothesises that the Turing
machine model captures the natural phenomena of computation.

\begin{notion} A problem is ``computable'' if it can be solved by transforming
a mathematical object, without ingenuity.
\end{notion}

Any attempt at a more definite notion of computability seems to arrive at a
philosophical impasse, where the notions of ``mathematical object'',
``transformation'', and ``ingenuity'' form a philosophical conundrum. The
indefinite notion however, is sufficient to state the following hypothesis:

\begin{hypothesis} \label{ths:problem-composition} If a problem $P$ can be
solved by solving a computable problem $Q$, immediately followed by solving a
computable problem $R$, then $P$ itself is computable. \end{hypothesis}

The hypothesis clearly holds as nothing is done other than solve the two
computable problems\footnote{Although, doing nothing, is also a philosophical
conundrum.}.  So any problem which can be solved by solving a finite sequence
of computable problems, is itself computable. We now arrive at an intuitive
notion of an algorithm:

\begin{notion} \label{ntn:problem-algorithm} An ``algorithm'' is a
specification of how a problem can be solved by solving a finite sequence of
computable problems, called ``steps''.\end{notion}

At this point, we have a recursive notion of computability with no basis. We
will gradually assume some problems to be fundamentally computable, gradually
evolving into the Church-Turing thesis.

An object of interest in computation is either one of a finite collection of
distinguished objects, or an object constructed by means of an algorithm.

\begin{notion} An ``alphabet'' is a finite collection of distinguished objects.
\end{notion}

\begin{notion} An object $x$ is an ``element'' of an alphabet $X$, written $x :
X$, if $x$ is one of the distinguished objects of $X$. We'll often refer to an
$x:X$ as a ``symbol''. \end{notion}

\begin{hypothesis}

We assume it to be fundamentally computable to consider the elements of an
alphabet in a sequence.

\end{hypothesis}

Due to the above hypothesis, we can now list the elements in an alphabet
typographically:

\begin{notation}

The elements of an alphabet are listed by listing the elements enclosed in
braces, and separated by commas.

\end{notation}

\textbf{Note:} Alphabets are toy-conception of the better known finite sets. We
choose only to draw the distinction for the purposes of a discussion about the
natural phenomena of computation. In particular, alphabets have a natural
correspondence to the real world. Alphabets often employed in computation in
practice is the alphabet of binary numbers $\set{0,1}$, the alphabet of
integers in the range $[0;2^{63}-1]$, the ASCII table, etc.

For instance, the alphabet $X$, consisting of just the symbols \symb{a},
\symb{b}, and \symb{c}, is denoted as $X=\set{\symb{a},\symb{b},\symb{c}}$.

\begin{hypothesis} We assume it to be fundamentally computable to decide
whether two elements $x:X$ and $y:X$ of the same alphabet $X$ are the same
symbol or not. \end{hypothesis}

\begin{notion}

A ``total function'' $f$ with ``domain'' $X$ and ``range'' $Y$, written
$f:X\rightarrow Y$, where $X$ and $Y$ are alphabets, has the following
properties:

\begin{enumerate}

\item For each $x : X$, $f$ has a unique \textbf{value} at $x$ in $Y$, written
$f\p{x} : Y$.

\item $X$, $Y$, and $f\p{x} : Y$ for each $x : X$ are all determined completely
by $f$.

\item $X$, $Y$, and $f\p{x} : Y$ for each $x : X$ completely determine $f$.

\end{enumerate}

\end{notion}

\begin{notion} A ``Cartesian product'' of alphabet $X$ and $Y$, written
$X\times Y$, is the collection of all tuples $\p{x,y}$, where $x:X$ and $y:Y$.
\end{notion}

The notions above are sufficient to define a computational model.

To this end, the concept of a Turing machine, due to Alan
Turing\cite{turing-1936-7}, forms perhaps the most well-founded, classical, and
intuitive conceptualization of computation. The conceptualization below is
heavily inspired by \cite{jones-1997}, \cite{homer-selman-2011}, and
\cite{sipser-2013}.

A Turing machine is a symbol-manipulating machine, working with a 1-dimensional
tape divided into discrete, equally sized squares, each occupied by one of the
symbols in a tape alphabet, $\Gamma$. The tape has a left edge, but extends
into infinity to the right.

A Turing machine is always in one of an alphabet of states, $Q$, and has a tape
head, always overlooking a particular square on the tape. A Turing machine
``computes'' by transitioning between states and working with the tape head.

The transition from one state to the next is uniquely determined by the current
state, and the symbol read off the overlooked square. A state transition bears
with it writing a new symbol to the overlooked square, and moving the tape head
one square to the left, or one square to the right.

\def\qstart{\ensuremath{q_{\text{start}}}}
\def\qhalt{\ensuremath{q_{\text{halt}}}}

A Turing machine has two distinguished states, the starting state, \qstart{},
and the halting state, \qhalt{}. A Turing machine computes by starting in state
\qstart{}, with the tape head on the left edge of the tape, and transitioning
states until the state \qhalt{} is reached. A Turing machine does not halt,
i.e.  continues transitioning states forever, if \qhalt{} is never reached.

The input of a Turing machine is a string of symbols $w$, from an
``input/output alphabet'', $\Sigma$. To facilitate computation with Turing
machine, the tape alphabet is the union of $\Sigma$, and an alphabet containing
just the special ``blank symbol'', \textvisiblespace. $w$ is written on tape by
starting at the left edge of the tape, and followed by an infinite sequence of
blank symbols.

The output of a Turing machine is the string of symbols on tape, starting at
the current position of the head when $\qhalt$ is reached, extending to the
right, until the first blank symbol is reached.

\begin{notion} \emph{Turing machine (TM).}

A Turing machine $M$, has 5 constituents, written
$M=\p{Q,\qstart,\qhalt,\Gamma, \delta}$, where

\begin{enumerate}

\item $Q$ is the state alphabet,

\item $\qstart :  Q$ is the starting state,

\item $\qhalt : Q$ is the halting state,

\item $\Gamma=\Sigma\cup\set{\text{\textvisiblespace}}$ is the tape alphabet,
where $\Sigma$ is the input/output alphabet,

\item $\delta:Q\setminus\set{\qhalt}\times\Gamma \rightarrow
Q\times\Gamma\times\set{\mathtt{L},\mathtt{R}}$, is the total transformation
function.

\end{enumerate}

\end{notion}

\begin{definition}

The \textbf{contents} of the tape of a TM is the sequence of symbols starting
at the left end of the tape, and extending until the last non-blank symbol.

\end{definition}

Since the input to a Turing machine is followed by an infinite sequence of
blank symbols, the contents of the tape at any given state of the TM, is
finite.

\begin{definition}

A \textbf{configuration} of a TM $M=\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, is
a triple $\chev{q,n,u}$, where

\begin{enumerate}

\item $q\in Q$ is the current state,

\item $n\in \mathbb{N}$ is the current offset of the head from the left end of
the tape, and

\item $u\in \Gamma^*$ is the current contents of the tape.

\end{enumerate}

\end{definition}

\begin{notation}

A configuration of a TM $M=\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, is denoted
by a concatenation of 3 components, $uqv$, where $u\in \Gamma^*$, $q\in Q$, and
$v\in \Gamma^+$, indicating that the TM is in state $q$, with $uv$ as the
contents of the tape, and the tape head is overlooking the first symbol of $v$.

\end{notation}

\begin{definition}

A TM configuration $C_x$ \textbf{yields}, or transitions to, a configuration
$C_y$, denoted $C_x\rightarrow C_y$, iff either

\begin{enumerate}

\item $C_x=uaq_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,L}$ and $C_y=uq_yacv$, or

\item $C_x=uq_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,R}$ and $C_y=ucq_yv$, or

\item $C_x=q_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,L}$ and $C_y=q_ycv$.

\end{enumerate}

\end{definition}


\pagebreak

\begin{notion}

A ``set'' is collection of distinguishable ``elements'', where each element is
either an element of an alphabet, or an object constructed by means of an algorithm. 

If a collection is a finite collection of distinguished objects, it is
trivially a set. Otherwise, an algorithm is required to distinguish the
elements.

\end{notion}

\begin{notion} An object $x$ is an element of a set $X$, written $x\in X$, if
$x$ is one of the distinguishable objects in $X$. \end{notion}

Notably, if $x\in X$ is a not a constant, there must exist an algorithm which
decides whether $x$ is one of the distinguishable objects in $X$ or not.

We can characterise a problem (computable, or not) by a mathematical function:

\begin{notion}

A ``mathematical function'' $f$ is a mathematical object with the following
properties:

\begin{enumerate}

\item $f$ has a ``domain'' $X$, and ``range'' $Y$, written $f:X\rightarrow Y$.

\item Both $X$ and $Y$ are sets.

\item For each $x \in X$, $f$ either has a unique \textbf{value} at $x$ in $Y$,
written $f\p{x} \in Y$, or $f\p{x}$ is undefined.

\item $X$, $Y$, and $f\p{x}\in Y$ for each $x\in X$ are all determined
completely by $f$.

\item $X$, $Y$, and $f\p{x}\in Y$ for each $x\in X$ completely determine $f$.

\end{enumerate}

\end{notion}

For now, all functions that we deal in are mathematical, and so we refer to
them simply as ``functions'' until further notice.

\begin{definition} A function $f:X\rightarrow Y$ is \textbf{total} if for each
$x\in X$, $f\p{x}\in Y$, and \textbf{partial} otherwise. \end{definition}

Unlike an algorithm, a mathematical function does not dictate how to compute a
solution to the problem. Instead, it is a characterisation of all the possible
algorithms which compute it.

\begin{notion}

An algorithm $A$ ``computes'' a mathematical function $f:X\rightarrow Y$, if
for all $x\in X$, the sequence of steps involved in $A$, transform a
representation of $x$, into a representation of $f\p{x}$, or it does not halt.

\end{notion}

\begin{notion} To ``compute a solution a problem'' means to compute a
mathematical function.  \end{notion}

We can now recast \refThesis{problem-composition} in terms of functions,
forming a notion of function composition:

\begin{hypothesis} A function $f:X\rightarrow Y$ is computable if for all $x\in
X$, $f\p{x}=h\p{g\p{x}}$, where $g:X\rightarrow Z$ and $h:Z\rightarrow Y$ are
both computable functions. \end{hypothesis}

Similarly, we can recast \refNotion{problem-algorithm} in terms of functions:

\begin{notion} An ``algorithm'' for computing a function $f:X\rightarrow Y$, is
a finite sequence of compositions of computable functions, $f_n \circ f_{n-1}
\circ f_0$, where $f_0$ has domain $X$, and $f_n$ has range $Y$. \end{notion}

We say that an algorithm, which computes a mathematical function $f$, is a
``computational interpretation'' of $f$. Depending on our choice of
mathematical foundations (the language we use to state mathematical functions),
a mathematical function may or may not have a computational interpretation,
i.e.  may or may not be computable. In the interests of the theory of
computability, we state the following axiom:

\begin{textaxiom} A mathematical function is either computable, not computable,
or it is not known whether it is computable or not. \end{textaxiom}

In some foundations of mathematics, a mathematical function may be known to be
computable, but we may not know an algorithm for computing it. For instance,
within classical mathematics, we can state a function which decides whether the
Goldbach conjecture\cite{dickson-1919-goldbach} holds or not. The conjecture is
that every even integer greater than 2 is a sum of two primes.  Consider now a
function $g:\mathbb{N}\rightarrow\set{0,1}$:

$$g\p{x} = \left\{
\begin{array}{l l}
1 & \text{the Goldbach conjecture is true} \\
0 & \text{otherwise}
\end{array}
\right.$$

The conjecture remains unproven, but an algorithm computing $g$ must exist as
every even integer $x$ greater than $2$ either is a sum of two primes, or it is
not. We can check this for any such $x$, by checking if the sum of any (of the
finitely many) pairs of primes less than $x$, equals $x$.

This is an example of an application of the so-called ``law of excluded
middle'' (LEM), which, in classical mathematics, is assumed as a universal
axiom. Roughly, LEM states that a property ranging over any domain, either
holds for the entire domain, or there's an element for which it doesn't. The
trouble with such a law is that if the domain is infinite, there is no finite
sequence of steps, which can verify, for every element, whether the property
holds or not.

We intend to refrain from applying LEM when dealing with infinite domains, and
subsume the following axiom:

\begin{textaxiom} A mathematical function is computable iff we know an
algorithm that computes it. \end{textaxiom}

This axiom does not disable us in defining functions which are not computable,
or functions which we do not know whether are computable or not. For instance,
it is now unknown whether $g$ is computable or not.

In general, a computable function, may have infinitely many algorithms which
compute it. For instance, an algorithm that computes $x*y$ (the product of two
integers, $x$ and $y$), is also computed by an algorithm that computes $x*y*1$,
or $x*y*1*1$, etc. Despite this, as will be shown more formally below, it is
not computable in general, to decide whether one algorithm computes the exact
same function as another.

\subsection{Turing Machines}

Such indefinite notions are useful for little else. We are left to take a
philosophical leap of faith, and fall prey to some choice of formalism.

To this end, the concept of a Turing machine, due to Alan
Turing\cite{turing-1936-7}, forms perhaps the most well-founded, classical, and
intuitive conceptualization of computation. The conceptualization below is
heavily inspired by \cite{jones-1997}, \cite{homer-selman-2011}, and
\cite{sipser-2013}.

A Turing machine is a symbol-manipulating machine, working with a 1-dimensional
tape divided into discrete, equally sized squares, each occupied by one of the
symbols in a tape alphabet, $\Gamma$. The tape has a left edge, but extends
into infinity to the right.

A Turing machine is always in one of an alphabet of states, $Q$, and has a tape
head, always overlooking a particular square on the tape. The transition from
one state to the next is uniquely determined by the current state, and the
symbol read off the overlooked square. A state transition bears with it writing
a new symbol to the overlooked square, and moving the tape head one square to
the left, or one square to the right.

A Turing machine has 2 distinguished states, the starting state, \qstart{}, and
the halting state, \qhalt{}. A Turing machine computes by starting in state
\qstart{}, with the tape head on the left edge of the tape, and transitioning
states until the state \qhalt{} is reached. A Turing machine does not halt,
i.e.  continues transitioning states forever, if \qhalt{} is never reached.

The input of a Turing machine is a string of symbols $w$, from an
``input/output alphabet'', $\Sigma$. To facilitate computation with Turing
machine, the tape alphabet is the union of $\Sigma$, and a singleton set,
containing just the special ``blank symbol'', \textvisiblespace. $w$ is then
written on tape in the obvious way, starting at the left edge of the tape, and
followed by an infinite sequence of blank symbols.  The output of a Turing
machine is the string of symbols on tape, starting at the current position of
the head when $\qhalt$ is reached, extending to the right, until the first
blank symbol is reached.

\begin{definition} \emph{Turing machine (TM).}

A Turing machine is a 5-tuple $\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, where

\begin{enumerate}

\item $Q$ is the state alphabet,

\item $\qstart\in Q$ is the starting state,

\item $\qhalt\in Q$ is the halting state,

\item $\Gamma=\Sigma\cup\set{\text{\textvisiblespace}}$ is the tape alphabet,
where $\Sigma$ is the input/output alphabet,

\item $\delta:Q\setminus\set{\qhalt}\times\Gamma \rightarrow
Q\times\Gamma\times\set{\mathtt{L},\mathtt{R}}$, is the total transformation
function.

\end{enumerate}

\end{definition}

\begin{definition}

The \textbf{contents} of the tape of a TM is the sequence of symbols starting
at the left end of the tape, and extending until the last non-blank symbol.

\end{definition}

Since the input to a Turing machine is followed by an infinite sequence of
blank symbols, the contents of the tape at any given state of the TM, is
finite.

\begin{definition}

A \textbf{configuration} of a TM $M=\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, is
a triple $\chev{q,n,u}$, where

\begin{enumerate}

\item $q\in Q$ is the current state,

\item $n\in \mathbb{N}$ is the current offset of the head from the left end of
the tape, and

\item $u\in \Gamma^*$ is the current contents of the tape.

\end{enumerate}

\end{definition}

\begin{notation}

A configuration of a TM $M=\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, is denoted
by a concatenation of 3 components, $uqv$, where $u\in \Gamma^*$, $q\in Q$, and
$v\in \Gamma^+$, indicating that the TM is in state $q$, with $uv$ as the
contents of the tape, and the tape head is overlooking the first symbol of $v$.

\end{notation}

\begin{definition}

A TM configuration $C_x$ \textbf{yields}, or transitions to, a configuration
$C_y$, denoted $C_x\rightarrow C_y$, iff either

\begin{enumerate}

\item $C_x=uaq_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,L}$ and $C_y=uq_yacv$, or

\item $C_x=uq_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,R}$ and $C_y=ucq_yv$, or

\item $C_x=q_xbv$, $\delta\p{q_x,b}=\chev{q_y,c,L}$ and $C_y=q_ycv$.

\end{enumerate}

\end{definition}

\begin{definition}

A TM $M=\chev{Q,\Gamma,\delta,\qstart,\qhalt}$, halts on input $w$, if there
exists a sequence of $M$-configurations, $\chev{C_0,C_1, \ldots, C_k}$, such
that

\begin{enumerate}

\item $C_0=\qstart w$,

\item $C_i\rightarrow C_{i+1}$,

\item $C_k=u\qhalt v$, for some $u\in\Gamma^*$, and $v\in\Gamma^+$.

\end{enumerate}

\end{definition}

\subsection{Church-Turing thesis}

\begin{hypothesis} \textit{Church-Turing thesis.}

No intuitive notion of an algorithm can compute a function that a Turing
machine cannot compute.

\end{hypothesis}

The Church-Turing thesis does not lend itself to mathematical proof. Rather, it
is a proposed explanation of the natural phenomena of computation. The
hypothesis remains to be disproven, and in the mean-while, computational models
more convenient than the Turing machine have emerged, some of them, even useful
in practice.

Some of these models have a formal specification, and so it lends itself to
formal proof that these models compute no more than a Turing machine does.

Our belief in the Church-Turing thesis has however, a notational advantage: to
show that a function $f$ is computable, it is sufficient to informally
describe, an algorithm for computing $f$. Due to the hypothesis, any
formalisation of the informal algorithm, will yield a computable algorithm,

This is sometimes called providing the ``pseudo-code'' for computing $f$, but can be said
of most ``code'' today in general.

Formal methods, due to their inherent complexity are seldom employed.

%%%%%

%As we are dealing with the transformation of mathematical objects, we can
%initially capture the notion of solving a problem by the concept of a
%``morphism'' from category theory.

%\begin{definition} A \textbf{morphism} $f$ from object $X$ to object $Y$ is
%written $f:X\rightarrow Y$. \end{definition}

%This does not yet tell us what the objects $X$ and $Y$ are, or how it is that
%$f$ ``morphs'' from $X$ to $Y$. We develop these concepts below. Drawing on
%category theory, in the spirit of \refThesis{problem-composition}, morphisms
%are composable:

%\begin{definition} The \textbf{composition} of morphisms $f:X\rightarrow Z$ and
%$g:Z\rightarrow Y$ is written $\p{g\circ f} : X \rightarrow Y$.
%\end{definition}

%The notion of an algorithm now becomes a finite composition of morphisms,
%provided that the morphisms in question capture solving \emph{computable}
%problems.  This demands that we specify what it means to ``morph'' from one
%object to another. First however, we consider what sort of objects we are
%interested in.


